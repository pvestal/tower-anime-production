"""LoRA Training router -- dataset and approval endpoints, with sub-routers for training and ingestion."""

import base64
import json
import logging
import os
import shutil
import urllib.request as _ur
from datetime import datetime
from pathlib import Path

from fastapi import APIRouter, HTTPException
from fastapi.responses import FileResponse

from packages.core.config import BASE_PATH, _PROJECT_DIR, OLLAMA_URL, VISION_MODEL
from packages.core.db import get_char_project_map
from packages.core.models import DatasetImageCreate, ReplenishRequest
from .feedback import (
    record_rejection,
    queue_regeneration,
)
from .ingest_router import ingest_router
from .training_router import training_router
from .router_approval import router as approval_router

logger = logging.getLogger(__name__)
router = APIRouter()
router.include_router(ingest_router)
router.include_router(training_router)
router.include_router(approval_router)

# ===================================================================
# Dataset endpoints
# ===================================================================

@router.get("/dataset/{character_name}")
async def get_dataset_info(character_name: str):
    """Get dataset images and approval status."""
    safe_name = character_name.lower().replace(" ", "_")
    dataset_path = BASE_PATH / safe_name
    images_path = dataset_path / "images"

    if not images_path.exists():
        return {"character": character_name, "images": []}

    approval_file = dataset_path / "approval_status.json"
    approval_status = {}
    if approval_file.exists():
        with open(approval_file) as f:
            approval_status = json.load(f)

    images = []
    for img in sorted(images_path.glob("*.png")):
        status = approval_status.get(img.name, "pending")
        caption_file = img.with_suffix(".txt")
        prompt = ""
        if caption_file.exists():
            prompt = caption_file.read_text().strip()
        meta_file = img.with_suffix(".meta.json")
        checkpoint_model = None
        if meta_file.exists():
            try:
                with open(meta_file) as mf:
                    checkpoint_model = json.load(mf).get("checkpoint_model")
            except Exception:
                pass
        images.append({
            "id": f"{safe_name}/{img.name}",
            "name": img.name,
            "status": status,
            "prompt": prompt,
            "created_at": datetime.fromtimestamp(img.stat().st_ctime).isoformat(),
            "checkpoint_model": checkpoint_model,
        })

    return {"character": character_name, "images": images}

@router.post("/dataset/{character_name}/images")
async def add_dataset_image(character_name: str, image: DatasetImageCreate):
    """Add an image entry to a character's dataset."""
    safe_name = character_name.lower().replace(" ", "_")
    dataset_path = BASE_PATH / safe_name / "images"

    if not dataset_path.exists():
        raise HTTPException(status_code=404, detail="Character dataset not found")

    image_id = f"{safe_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    return {"message": "Image entry created", "image_id": image_id}

@router.get("/characters/{character_slug}/reference-images")
async def list_reference_images(character_slug: str):
    """List reference images for a character (used by IP-Adapter)."""
    ref_dir = BASE_PATH / character_slug / "reference_images"
    if not ref_dir.exists():
        return {"character_slug": character_slug, "images": [], "count": 0}
    images = sorted([f.name for f in ref_dir.iterdir() if f.suffix.lower() in (".png", ".jpg", ".jpeg", ".webp")])
    return {"character_slug": character_slug, "images": images, "count": len(images)}

@router.post("/characters/{character_slug}/reference-images")
async def add_reference_image(character_slug: str, body: dict):
    """Copy an approved image to reference_images/ for IP-Adapter conditioning."""
    ref_dir = BASE_PATH / character_slug / "reference_images"
    ref_dir.mkdir(parents=True, exist_ok=True)

    image_name = body.get("image_name")
    if image_name:
        source = BASE_PATH / character_slug / "images" / image_name
        if not source.exists():
            raise HTTPException(status_code=404, detail=f"Image '{image_name}' not found")
        dest = ref_dir / image_name
        shutil.copy2(source, dest)
        logger.info(f"Reference image added: {character_slug}/{image_name}")
        return {"message": f"Added {image_name} as reference", "path": str(dest)}

    raise HTTPException(status_code=400, detail="Provide image_name")

@router.delete("/characters/{character_slug}/reference-images/{image_name}")
async def remove_reference_image(character_slug: str, image_name: str):
    """Remove a reference image."""
    ref_path = BASE_PATH / character_slug / "reference_images" / image_name
    if not ref_path.exists():
        raise HTTPException(status_code=404, detail="Reference image not found")
    ref_path.unlink()
    return {"message": f"Removed reference image {image_name}"}

@router.get("/dataset/{character_name}/image/{image_name}")
async def get_image(character_name: str, image_name: str):
    """Serve an image file."""
    safe_name = character_name.lower().replace(" ", "_")
    image_path = BASE_PATH / safe_name / "images" / image_name

    if not image_path.exists():
        placeholder = _PROJECT_DIR / "static" / "placeholder.png"
        if placeholder.exists():
            return FileResponse(placeholder)
        raise HTTPException(status_code=404, detail="Image not found")

    return FileResponse(image_path)

@router.get("/dataset/{character_name}/image/{image_name}/metadata")
async def get_image_metadata(character_name: str, image_name: str):
    """Get generation metadata for a specific image."""
    safe_name = character_name.lower().replace(" ", "_")
    image_path = BASE_PATH / safe_name / "images" / image_name
    meta_path = image_path.with_suffix(".meta.json")

    if not image_path.exists():
        raise HTTPException(status_code=404, detail="Image not found")

    if meta_path.exists():
        with open(meta_path) as f:
            return json.load(f)

    # Fallback: partial metadata from .txt sidecar + project info
    char_map = await get_char_project_map()
    db_info = char_map.get(safe_name, {})
    caption_file = image_path.with_suffix(".txt")
    return {
        "seed": None,
        "design_prompt": db_info.get("design_prompt", ""),
        "full_prompt": caption_file.read_text().strip() if caption_file.exists() else "",
        "checkpoint_model": db_info.get("checkpoint_model", ""),
        "cfg_scale": db_info.get("cfg_scale"),
        "steps": db_info.get("steps"),
        "source": "backfill_partial",
        "backfilled": True,
    }


# ===================================================================
# Library endpoint (single call for all approved images)
# ===================================================================

@router.get("/library")
async def get_library():
    """Get all approved images across all characters in one fast call."""
    if not BASE_PATH.exists():
        return {"images": [], "characters": []}

    char_map = await get_char_project_map()
    images = []
    char_counts: dict[str, dict] = {}

    for char_dir in sorted(BASE_PATH.iterdir()):
        if not char_dir.is_dir():
            continue
        images_path = char_dir / "images"
        if not images_path.exists():
            continue

        slug = char_dir.name
        if slug == "_unclassified":
            db_info = {"name": "Unclassified"}
        else:
            db_info = char_map.get(slug)
            if not db_info:
                continue

        approval_file = char_dir / "approval_status.json"
        if not approval_file.exists():
            continue
        with open(approval_file) as f:
            approval_status = json.load(f)

        approved_names = {name for name, st in approval_status.items() if st == "approved"}
        if not approved_names:
            continue

        # Filter out stale entries (files moved/deleted but still in approval_status)
        existing_files = set(f.name for f in images_path.iterdir() if f.suffix == ".png")
        approved_names &= existing_files
        if not approved_names:
            continue

        char_name = db_info["name"]
        project_name = db_info.get("project_name", "Unknown")
        checkpoint_model = db_info.get("checkpoint_model", "unknown")
        char_counts[slug] = {
            "slug": slug, "name": char_name, "approved": len(approved_names),
            "project_name": project_name, "checkpoint_model": checkpoint_model,
        }

        for name in sorted(approved_names):
            images.append({
                "slug": slug,
                "characterName": char_name,
                "name": name,
                "project_name": project_name,
                "checkpoint_model": checkpoint_model,
            })

    characters = sorted(char_counts.values(), key=lambda c: c["name"])

    # Deduplicated filter lists for frontend pills
    projects = sorted({c["project_name"] for c in char_counts.values()})
    models = sorted({c["checkpoint_model"] for c in char_counts.values() if c["checkpoint_model"]})

    return {"images": images, "characters": characters, "projects": projects, "models": models}


# ===================================================================
# Dataset statistics (real filesystem counts for Analytics)
# ===================================================================

@router.get("/dataset-stats")
async def dataset_stats(project_name: str = None):
    """Aggregate real dataset stats from filesystem approval_status.json files.

    Returns per-character approved/pending/rejected counts and totals.
    Optionally filtered by project_name.
    """
    if not BASE_PATH.exists():
        return {"characters": [], "totals": {"approved": 0, "pending": 0, "rejected": 0, "total": 0}}

    char_map = await get_char_project_map()
    characters = []
    totals = {"approved": 0, "pending": 0, "rejected": 0, "total": 0}

    for char_dir in sorted(BASE_PATH.iterdir()):
        if not char_dir.is_dir():
            continue
        images_path = char_dir / "images"
        if not images_path.exists():
            continue

        slug = char_dir.name
        if slug == "_unclassified":
            db_info = {"name": "Unclassified", "project_name": ""}
            # For project filter, skip _unclassified unless no filter
            if project_name:
                continue
        else:
            db_info = char_map.get(slug)
            if not db_info:
                continue
            if project_name and db_info.get("project_name") != project_name:
                continue

        approval_file = char_dir / "approval_status.json"
        approval_status = {}
        if approval_file.exists():
            try:
                with open(approval_file) as f:
                    approval_status = json.load(f)
            except (json.JSONDecodeError, IOError):
                pass

        image_files = list(images_path.glob("*.png"))
        approved = 0
        pending = 0
        rejected = 0
        model_counts: dict[str, int] = {}  # checkpoint → count of approved images
        for img in image_files:
            status = approval_status.get(img.name, "pending")
            if status == "approved":
                approved += 1
                # Track which checkpoint model generated each approved image
                meta_file = img.with_suffix(".meta.json")
                if meta_file.exists():
                    try:
                        with open(meta_file) as mf:
                            ck = json.load(mf).get("checkpoint_model")
                            model_counts[ck or "unknown"] = model_counts.get(ck or "unknown", 0) + 1
                    except Exception:
                        model_counts["unknown"] = model_counts.get("unknown", 0) + 1
                else:
                    model_counts["no_meta"] = model_counts.get("no_meta", 0) + 1
            elif status == "rejected":
                rejected += 1
            else:
                pending += 1

        total = approved + pending + rejected
        if total == 0:
            continue

        # Determine dominant model and flag mixed datasets
        dominant_model = max(model_counts, key=model_counts.get) if model_counts else None
        is_mixed = len([m for m in model_counts if m not in ("unknown", "no_meta")]) > 1

        characters.append({
            "slug": slug,
            "name": db_info.get("name", slug),
            "project_name": db_info.get("project_name", ""),
            "approved": approved,
            "pending": pending,
            "rejected": rejected,
            "total": total,
            "approval_rate": round(approved / total, 3) if total else 0,
            "model_breakdown": model_counts,
            "dominant_model": dominant_model,
            "is_mixed_models": is_mixed,
        })

        totals["approved"] += approved
        totals["pending"] += pending
        totals["rejected"] += rejected
        totals["total"] += total

    return {"characters": characters, "totals": totals}


# ===================================================================
# Vision identify (open-ended character recognition)
# ===================================================================

@router.get("/identify/{character_slug}/{image_name}")
async def identify_character(character_slug: str, image_name: str):
    """Ask vision model to identify the character in an image (open-ended)."""
    image_path = BASE_PATH / character_slug / "images" / image_name
    if not image_path.exists():
        raise HTTPException(status_code=404, detail="Image not found")

    img_b64 = base64.b64encode(image_path.read_bytes()).decode()

    prompt = (
        "Describe the primary character in this frame -- species, appearance, colors, "
        "clothing, accessories. If you recognize them from any franchise, say who they are.\n\n"
        'Reply with JSON: {"description": "...", "suggested_name": "..."}'
    )

    payload = json.dumps({
        "model": VISION_MODEL,
        "messages": [{"role": "user", "content": prompt, "images": [img_b64]}],
        "stream": False,
        "options": {"temperature": 0.3, "num_predict": 300},
    }).encode()

    try:
        req = _ur.Request(
            f"{OLLAMA_URL}/api/chat", data=payload,
            headers={"Content-Type": "application/json"},
        )
        resp = json.loads(_ur.urlopen(req, timeout=30).read())
        raw = resp.get("message", {}).get("content", "").strip()
    except Exception as e:
        logger.error(f"Vision identify failed for {character_slug}/{image_name}: {e}")
        raise HTTPException(status_code=502, detail=f"Vision model error: {e}")

    # Try to extract JSON from response
    start, end = raw.find("{"), raw.rfind("}")
    if start != -1 and end > start:
        try:
            parsed = json.loads(raw[start:end + 1])
            return {
                "description": parsed.get("description", raw),
                "suggested_name": parsed.get("suggested_name", ""),
            }
        except json.JSONDecodeError:
            pass

    return {"description": raw, "suggested_name": ""}


# ===================================================================
# Replenishment — proactive deficit filling
# ===================================================================

@router.post("/replenish")
async def start_replenish(body: ReplenishRequest):
    """Kick off proactive replenishment for all characters below target.

    Scans characters in the project (or all projects), identifies those
    below target_per_character approved images, and runs generate → vision
    review → loop until targets are met or safety limits are hit.

    Returns a task_id for polling progress via GET /api/training/replenish/{task_id}.
    """
    from packages.core.replenishment import fill_deficit

    task_id = await fill_deficit(
        project_name=body.project_name,
        target=body.target_per_character,
        batch_size=body.max_batch_size,
        max_iterations=body.max_iterations_per_char,
        auto_reject_threshold=body.auto_reject_threshold,
        auto_approve_threshold=body.auto_approve_threshold,
        strategy=body.strategy,
    )

    return {
        "task_id": task_id,
        "status": "running",
        "message": f"Replenishment started (target: {body.target_per_character})",
        "poll_url": f"/api/training/replenish/{task_id}",
    }


@router.get("/replenish/{task_id}")
async def get_replenish_status(task_id: str):
    """Poll replenishment task progress.

    Returns per-character progress: slug, approved_before, approved_now,
    target, generated, reviewed, status.
    """
    from packages.core.replenishment import get_replenish_task

    task = get_replenish_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail=f"Replenish task '{task_id}' not found")
    return task
