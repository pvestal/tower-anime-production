#!/usr/bin/env python3
"""Analyze consistency gaps and identify improvement areas"""

import numpy as np
from pathlib import Path
from PIL import Image
import json

def analyze_variation_impact():
    """Analyze what causes consistency drops"""

    print("=" * 60)
    print("CONSISTENCY GAP ANALYSIS")
    print("=" * 60)

    # Data from our tests
    variations = {
        "standing pose, full body": 0.902,
        "sitting pose, reading a book": 0.859,  # LOWEST
        "side profile, looking at sunset": 0.922,
        "action pose, dynamic movement": 0.904,
        "close-up portrait, smiling": 0.944  # HIGHEST
    }

    print("\nüìä Variation Impact Analysis:")
    print("-" * 40)

    # Sort by similarity
    sorted_vars = sorted(variations.items(), key=lambda x: x[1])

    print("Worst performing variations:")
    for prompt, score in sorted_vars[:2]:
        print(f"  {score:.3f} - {prompt}")

    print("\nBest performing variations:")
    for prompt, score in sorted_vars[-2:]:
        print(f"  {score:.3f} - {prompt}")

    # Identify patterns
    print("\nüîç Pattern Analysis:")

    # Pose complexity
    complex_poses = ["sitting pose, reading a book", "action pose, dynamic movement"]
    simple_poses = ["standing pose, full body", "close-up portrait, smiling"]

    complex_avg = np.mean([variations[p] for p in complex_poses])
    simple_avg = np.mean([variations[p] for p in simple_poses])

    print(f"  Complex poses average: {complex_avg:.3f}")
    print(f"  Simple poses average: {simple_avg:.3f}")
    print(f"  Difference: {simple_avg - complex_avg:.3f}")

    # View angle impact
    profile_views = ["side profile, looking at sunset"]
    frontal_views = ["standing pose, full body", "close-up portrait, smiling"]

    profile_avg = np.mean([variations[p] for p in profile_views])
    frontal_avg = np.mean([variations[p] for p in frontal_views])

    print(f"\n  Profile view average: {profile_avg:.3f}")
    print(f"  Frontal view average: {frontal_avg:.3f}")

    # Props/objects impact
    with_props = ["sitting pose, reading a book"]
    without_props = ["standing pose, full body", "close-up portrait, smiling", "side profile, looking at sunset"]

    props_avg = np.mean([variations[p] for p in with_props])
    no_props_avg = np.mean([variations[p] for p in without_props])

    print(f"\n  With props average: {props_avg:.3f}")
    print(f"  Without props average: {no_props_avg:.3f}")
    print(f"  Props impact: {no_props_avg - props_avg:.3f} loss")

def identify_improvement_areas():
    """Identify specific areas for improvement"""

    print("\n" + "=" * 60)
    print("IMPROVEMENT OPPORTUNITIES")
    print("=" * 60)

    improvements = {
        "IPAdapter Weight Tuning": {
            "current": "0.8-0.85",
            "optimal": "0.9-0.95 for anime",
            "impact": "+2-3%",
            "reason": "Anime style needs stronger reference influence"
        },
        "Multi-Reference IPAdapter": {
            "current": "Single reference image",
            "optimal": "3-5 reference angles",
            "impact": "+5-8%",
            "reason": "Multiple views provide better character understanding"
        },
        "Character-Specific LoRA": {
            "current": "None",
            "optimal": "Fine-tuned LoRA per character",
            "impact": "+10-15%",
            "reason": "Learns specific character features"
        },
        "Pose Conditioning": {
            "current": "Text-only pose description",
            "optimal": "OpenPose/ControlNet skeleton",
            "impact": "+5-7%",
            "reason": "Precise pose control maintains features"
        },
        "Face-Specific Enhancement": {
            "current": "Full image IPAdapter",
            "optimal": "IPAdapter-FaceID Plus",
            "impact": "+3-5%",
            "reason": "Focus on facial features"
        },
        "Prompt Engineering": {
            "current": "Basic descriptions",
            "optimal": "Structured character tags",
            "impact": "+2-4%",
            "reason": "Consistent feature descriptions"
        }
    }

    total_potential = 0
    for name, details in improvements.items():
        print(f"\nüìà {name}")
        print(f"  Current: {details['current']}")
        print(f"  Optimal: {details['optimal']}")
        print(f"  Impact: {details['impact']}")
        print(f"  Why: {details['reason']}")

        # Extract impact percentage
        import re
        match = re.search(r'\+(\d+)-(\d+)%', details['impact'])
        if match:
            avg_impact = (int(match.group(1)) + int(match.group(2))) / 2
            total_potential += avg_impact

    print("\n" + "=" * 60)
    print(f"TOTAL POTENTIAL IMPROVEMENT: +{total_potential:.0f}%")
    print(f"Projected consistency: {0.906 * (1 + total_potential/100):.3f}")
    print("=" * 60)

def generate_optimization_config():
    """Generate optimized configuration"""

    print("\nüìù OPTIMIZED CONFIGURATION")
    print("-" * 40)

    config = {
        "ipadapter": {
            "weight": 0.92,
            "weight_type": "standard",
            "start_at": 0.0,
            "end_at": 0.85,  # Reduce influence in final steps
            "noise": 0.0
        },
        "sampler": {
            "steps": 30,  # More steps for consistency
            "cfg": 8.0,  # Higher CFG for stronger conditioning
            "sampler_name": "dpmpp_2m_sde",  # Better for character consistency
            "scheduler": "karras"
        },
        "prompt_template": {
            "structure": "{character_name}, {core_features}, {pose}, {expression}, {outfit}, masterpiece, best quality",
            "negative": "low quality, blurry, deformed, inconsistent features, different character, off-model"
        },
        "multi_reference": {
            "angles": ["front", "side", "three-quarter"],
            "expressions": ["neutral", "smiling"],
            "min_references": 3
        }
    }

    print(json.dumps(config, indent=2))

    # Save config
    with open('/opt/tower-anime-production/optimized_config.json', 'w') as f:
        json.dump(config, f, indent=2)
    print("\n‚úÖ Saved to optimized_config.json")

def test_optimization_ideas():
    """Test specific optimization ideas"""

    print("\nüß™ QUICK OPTIMIZATION TESTS")
    print("-" * 40)

    tests = [
        {
            "name": "Higher IPAdapter Weight",
            "change": "weight: 0.85 ‚Üí 0.92",
            "expected": "+2-3% consistency",
            "risk": "May reduce pose variation"
        },
        {
            "name": "Structured Prompts",
            "change": "Add character tags systematically",
            "expected": "+2-4% consistency",
            "risk": "None"
        },
        {
            "name": "Negative Prompt Enhancement",
            "change": "Add 'different character, off-model'",
            "expected": "+1-2% consistency",
            "risk": "None"
        },
        {
            "name": "CFG Scale Increase",
            "change": "cfg: 7.0 ‚Üí 8.0",
            "expected": "+1-2% consistency",
            "risk": "Slight quality reduction"
        }
    ]

    for test in tests:
        print(f"\nüîß {test['name']}")
        print(f"  Change: {test['change']}")
        print(f"  Expected: {test['expected']}")
        print(f"  Risk: {test['risk']}")

if __name__ == "__main__":
    analyze_variation_impact()
    identify_improvement_areas()
    generate_optimization_config()
    test_optimization_ideas()

    print("\nüéØ RECOMMENDED NEXT STEPS:")
    print("1. Test with weight=0.92 immediately (+2-3%)")
    print("2. Implement multi-reference system (+5-8%)")
    print("3. Add ControlNet for pose stability (+5-7%)")
    print("4. Train character LoRA if <95% after above (+10-15%)")
    print("\nTarget: 95%+ consistency achievable with these improvements")